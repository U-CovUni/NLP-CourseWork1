{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNldAdp2sAM6OCUhH8QVtsH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/U-CovUni/NLP-CourseWork1/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "87GxFYQmxGGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb0a1420-6a3f-44fc-9169-9e4428f21664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Convolutional Neural Network...\n",
            "Epoch 1/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 5s/step - accuracy: 0.4870 - loss: 1.0345 - val_accuracy: 0.6234 - val_loss: 0.8579\n",
            "Epoch 2/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 5s/step - accuracy: 0.7348 - loss: 0.6321 - val_accuracy: 0.6110 - val_loss: 0.8437\n",
            "Epoch 3/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 5s/step - accuracy: 0.8701 - loss: 0.3764 - val_accuracy: 0.6004 - val_loss: 0.9348\n",
            "Epoch 4/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 5s/step - accuracy: 0.9403 - loss: 0.1860 - val_accuracy: 0.6128 - val_loss: 1.2047\n",
            "Epoch 5/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 5s/step - accuracy: 0.9813 - loss: 0.0644 - val_accuracy: 0.5950 - val_loss: 1.5369\n",
            "Epoch 6/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 5s/step - accuracy: 0.9936 - loss: 0.0181 - val_accuracy: 0.5861 - val_loss: 1.7496\n",
            "Epoch 7/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 6s/step - accuracy: 0.9978 - loss: 0.0093 - val_accuracy: 0.5968 - val_loss: 1.9586\n",
            "Epoch 8/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 5s/step - accuracy: 0.9982 - loss: 0.0167 - val_accuracy: 0.5915 - val_loss: 2.0792\n",
            "Epoch 9/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 5s/step - accuracy: 0.9989 - loss: 0.0065 - val_accuracy: 0.6004 - val_loss: 2.0736\n",
            "Epoch 10/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 5s/step - accuracy: 0.9989 - loss: 0.0044 - val_accuracy: 0.6021 - val_loss: 2.1091\n",
            "18/18 - 15s - 833ms/step - accuracy: 0.6021 - loss: 2.1091\n",
            "CNN Test Accuracy: 0.6021314263343811\n"
          ]
        }
      ],
      "source": [
        "# Importing the dependencies\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, LSTM, Embedding, GlobalMaxPool1D, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/semEval.csv')\n",
        "\n",
        "# Converting the stance labels to numerical format\n",
        "stance_mapping = {'AGAINST': 0, 'FAVOR': 1, 'NONE': 2}\n",
        "data['Stance'] = data['Stance'].map(stance_mapping)\n",
        "\n",
        "# Splitting the data into training and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing the CountVectorizer (Bag of Words)\n",
        "vectorizer = CountVectorizer(max_features=10000, stop_words='english')\n",
        "\n",
        "# Fitting and transforming the training data, transform the test data\n",
        "X_train = vectorizer.fit_transform(train_data['Tweet']).toarray()\n",
        "X_test = vectorizer.transform(test_data['Tweet']).toarray()\n",
        "\n",
        "# Extracting the labels\n",
        "y_train = train_data['Stance']\n",
        "y_test = test_data['Stance']\n",
        "\n",
        "# Encoding the labels\n",
        "encoder = LabelEncoder()\n",
        "y_train_encoded = encoder.fit_transform(y_train)\n",
        "y_test_encoded = encoder.transform(y_test)\n",
        "\n",
        "# Converting labels to categorical (one-hot encoding)\n",
        "y_train_categorical = to_categorical(y_train_encoded, num_classes=3)\n",
        "y_test_categorical = to_categorical(y_test_encoded, num_classes=3)\n",
        "\n",
        "# Fitting Convolutional Neural Network (CNN)\n",
        "def create_cnn_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv1D(128, 5, activation='relu', input_shape=(input_shape, 1)),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.5),\n",
        "        Conv1D(128, 5, activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "# Train and evaluate models\n",
        "input_shape = X_train.shape[1]\n",
        "\n",
        "# Reshape data for CNN\n",
        "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "\n",
        "cnn_model = create_cnn_model(input_shape)\n",
        "print(\"\\nTraining Convolutional Neural Network...\")\n",
        "cnn_history = cnn_model.fit(X_train_cnn, y_train_categorical, epochs=10, validation_data=(X_test_cnn, y_test_categorical), batch_size=32)\n",
        "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test_cnn, y_test_categorical, verbose=2)\n",
        "print(f'CNN Test Accuracy: {cnn_accuracy}')"
      ]
    }
  ]
}